{"cells":[{"cell_type":"markdown","source":["Name : Everth Palomino Lanchipa"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fd934950-0fde-4f6e-9bf1-2ec3ab98b26e"}}},{"cell_type":"markdown","source":["Se comienza descargando el archivo rows.json en la ruta /dbfs/tmp"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c952f08d-6673-4b16-b60c-09f0e430c361"}}},{"cell_type":"code","source":["%scala\nimport java.net.URL\nimport java.io.File\nimport org.apache.commons.io.FileUtils\nimport org.apache.spark.sql.SparkSession\nimport org.apache.spark.sql.{DataFrame, Row, SparkSession}\nimport org.apache.spark.sql.types.{IntegerType, StringType, StructField, StructType}\nimport java.util.regex.Pattern\n\nval spark = SparkSession\n  .builder()\n  .appName(\"AppBluesmile_scala\")\n  .enableHiveSupport()\n  .getOrCreate()\n\nval  sc = spark.sparkContext\n\nval tmpFile = new File(\"/dbfs/tmp/rows.json\")\nFileUtils.copyURLToFile(new URL(\"https://health.data.ny.gov/api/views/jxy9-yhdk/rows.json?accessType=DOWNLOAD\"), tmpFile)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fe06361a-5f76-49d7-a8a0-0aeae130b1f7"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">import java.net.URL\nimport java.io.File\nimport org.apache.commons.io.FileUtils\nimport org.apache.spark.sql.SparkSession\nimport org.apache.spark.sql.{DataFrame, Row, SparkSession}\nimport org.apache.spark.sql.types.{IntegerType, StringType, StructField, StructType}\nimport java.util.regex.Pattern\nspark: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@559e02e8\nsc: org.apache.spark.SparkContext = org.apache.spark.SparkContext@3070c240\ntmpFile: java.io.File = /dbfs/tmp/rows.json\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">import java.net.URL\nimport java.io.File\nimport org.apache.commons.io.FileUtils\nimport org.apache.spark.sql.SparkSession\nimport org.apache.spark.sql.{DataFrame, Row, SparkSession}\nimport org.apache.spark.sql.types.{IntegerType, StringType, StructField, StructType}\nimport java.util.regex.Pattern\nspark: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@559e02e8\nsc: org.apache.spark.SparkContext = org.apache.spark.SparkContext@3070c240\ntmpFile: java.io.File = /dbfs/tmp/rows.json\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Question #1: Spark SQL's Native JSON Support | Question # 2 Working with Nested Data"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5daf34da-7973-463c-a932-a546e59efd09"}}},{"cell_type":"code","source":["# Question #1: Spark SQL's Native JSON Support | Question # 2 Working with Nested Data\nfrom pyspark.sql.functions import explode\nfrom pyspark.sql import SparkSession\nfrom pyspark import SparkContext\nfrom pyspark.sql import SQLContext\nfrom pyspark.sql.functions import regexp_extract\n\n\nspark_session = SparkSession \\\n    .builder \\\n    .appName(\"AppBlueSmile_pypark\") \\\n    .enableHiveSupport() \\\n    .getOrCreate()\n\nspark_session.read.json('/tmp/rows.json', multiLine=True).select(explode(\"data\").alias(\"data\")).registerTempTable(\"tb_tmp_newdata\")\nsqlContext.sql(\"SELECT data[8] AS year, data[9] AS first_name, data[10] AS country, data[11] AS sex, data[12] AS name_count FROM tb_tmp_newdata\").registerTempTable(\"tb_tmp_babynames\")\ndf_baby_names= spark.sql('Select * from tb_tmp_babynames')\ndf_baby_names.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f330784e-c0d5-47cb-b16b-102b4164a297"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"df_baby_names","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"year","nullable":true,"type":"string"},{"metadata":{},"name":"first_name","nullable":true,"type":"string"},{"metadata":{},"name":"country","nullable":true,"type":"string"},{"metadata":{},"name":"sex","nullable":true,"type":"string"},{"metadata":{},"name":"name_count","nullable":true,"type":"string"}],"type":"struct"},"tableIdentifier":null}],"data":"<div class=\"ansiout\">+----+----------+-----------+---+----------+\n|year|first_name|    country|sex|name_count|\n+----+----------+-----------+---+----------+\n|2007|      ZOEY|      KINGS|  F|        11|\n|2007|      ZOEY|    SUFFOLK|  F|         6|\n|2007|      ZOEY|     MONROE|  F|         6|\n|2007|      ZOEY|       ERIE|  F|         9|\n|2007|       ZOE|     ULSTER|  F|         5|\n|2007|       ZOE|WESTCHESTER|  F|        24|\n|2007|       ZOE|      BRONX|  F|        13|\n|2007|       ZOE|   NEW YORK|  F|        55|\n|2007|       ZOE|     NASSAU|  F|        15|\n|2007|       ZOE|       ERIE|  F|         6|\n|2007|       ZOE|    SUFFOLK|  F|        14|\n|2007|       ZOE|      KINGS|  F|        34|\n|2007|       ZOE|     MONROE|  F|         9|\n|2007|       ZOE|     QUEENS|  F|        26|\n|2007|       ZOE|     ALBANY|  F|         5|\n|2007|     ZISSY|   ROCKLAND|  F|         5|\n|2007|     ZISSY|      KINGS|  F|        27|\n|2007|      ZION|      KINGS|  M|        15|\n|2007|      ZION|      BRONX|  M|        14|\n|2007|       ZEV|   ROCKLAND|  M|         6|\n+----+----------+-----------+---+----------+\nonly showing top 20 rows\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----+----------+-----------+---+----------+\nyear|first_name|    country|sex|name_count|\n+----+----------+-----------+---+----------+\n2007|      ZOEY|      KINGS|  F|        11|\n2007|      ZOEY|    SUFFOLK|  F|         6|\n2007|      ZOEY|     MONROE|  F|         6|\n2007|      ZOEY|       ERIE|  F|         9|\n2007|       ZOE|     ULSTER|  F|         5|\n2007|       ZOE|WESTCHESTER|  F|        24|\n2007|       ZOE|      BRONX|  F|        13|\n2007|       ZOE|   NEW YORK|  F|        55|\n2007|       ZOE|     NASSAU|  F|        15|\n2007|       ZOE|       ERIE|  F|         6|\n2007|       ZOE|    SUFFOLK|  F|        14|\n2007|       ZOE|      KINGS|  F|        34|\n2007|       ZOE|     MONROE|  F|         9|\n2007|       ZOE|     QUEENS|  F|        26|\n2007|       ZOE|     ALBANY|  F|         5|\n2007|     ZISSY|   ROCKLAND|  F|         5|\n2007|     ZISSY|      KINGS|  F|        27|\n2007|      ZION|      KINGS|  M|        15|\n2007|      ZION|      BRONX|  M|        14|\n2007|       ZEV|   ROCKLAND|  M|         6|\n+----+----------+-----------+---+----------+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Question #3: Executing Full Data Pipeline"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"50bb24d1-fc43-43ce-b35a-882a9b7a60e9"}}},{"cell_type":"code","source":["#Question #3: Executing Full Data Pipelines\n#Case 1 : Valida la existencia del archivo rows.json no tiene relevancia ya que en cada ejecucion consulta a la pagina y descarga el archivo.\n#Case 2: Si el archivo rows.json no ha sido descargado,lo descarga la primera vez, en la siguiente iteracion ya no lo descarga.\nfile_exists= dbutils.fs.ls(\"/tmp/rows.json\")\n#Case 1\nif  not file_exists:\n    nextStep=dbutils.notebook.run(\n        \"extract_json\", 180)\n    if nextStep ==\"Clean\":\n        dbutils.notebook.run(\n        \"procesamiento_json\", 180)\n#Case 2\nelse:\n    dbutils.notebook.run(\n        \"procesamiento_json\", 180)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7a3bbeb8-e362-47bc-8931-2de94838d906"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Question 4 Analyzing the Data"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"90d1e31f-4a6f-40f3-a789-af827a3e5ff3"}}},{"cell_type":"code","source":["#Question 4 Analyzing the Data\ndf_data_input = spark_session.sql('select year,name,cnt from (select year,name,cnt ,dense_rank() OVER (PARTITION BY year ORDER BY cnt DESC) as rank from (  select substr(first_name,1,1) as name,year,count(*) as cnt from tb_tmp_babynames group by name,year) ) where rank = 1')\ndf_data_input.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"05f22bb4-a976-4bfb-8e46-e716d5861045"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"df_data_input","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"year","nullable":true,"type":"string"},{"metadata":{},"name":"name","nullable":true,"type":"string"},{"metadata":{},"name":"cnt","nullable":false,"type":"long"}],"type":"struct"},"tableIdentifier":null}],"data":"<div class=\"ansiout\">+----+----+----+\n|year|name| cnt|\n+----+----+----+\n|2007|   A| 913|\n|2008|   A| 936|\n|2009|   A| 900|\n|2010|   A| 884|\n|2011|   A| 915|\n|2012|   A| 880|\n|2013|   A| 895|\n|2014|   A|1245|\n|2015|   A| 918|\n|2016|   A| 935|\n|2017|   A| 883|\n|2018|   A| 875|\n+----+----+----+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----+----+----+\nyear|name| cnt|\n+----+----+----+\n2007|   A| 913|\n2008|   A| 936|\n2009|   A| 900|\n2010|   A| 884|\n2011|   A| 915|\n2012|   A| 880|\n2013|   A| 895|\n2014|   A|1245|\n2015|   A| 918|\n2016|   A| 935|\n2017|   A| 883|\n2018|   A| 875|\n+----+----+----+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["#Data Visualization\nimport matplotlib.pyplot as plt\neje_x = df_data_input.toPandas()['year'].tolist()\neje_y = df_data_input.toPandas()['cnt'].tolist()\nplt.bar(eje_x, eje_y)\nplt.ylabel('Cantidad')\nplt.xlabel('year')\nplt.title('Most popular letter baby names / year')\nplt.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4eac0f09-60a2-4159-b387-2009259bb6be"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"/plots/2c361c8c-2a5c-45ce-b51b-6d6eb35c2a04.png","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"image","arguments":{}}},"output_type":"display_data","data":{"image/png":"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"}}],"execution_count":0},{"cell_type":"markdown","source":["Log Processing"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8854cd7d-88ed-413f-91d8-ef7829811dce"}}},{"cell_type":"code","source":["#Se lee el archivo de log que esta guardado en la ruta /FileStore/log.txt\nlog_raw = spark.read.text('/FileStore/log.txt')\n#Definicion de expresiones regulares para extraer datos del log.\nhost_pattern = r'(^\\S+\\.[\\S+\\.]+\\S+)\\s'\nts_pattern = r'\\[(\\d{2}/\\w{3}/\\d{4}:\\d{2}:\\d{2}:\\d{2} -\\d{4})]'\nmethod_uri_protocol_pattern = r'\\\"(\\S+)\\s(\\S+)\\s*(\\S*)\\\"'\nstatus_pattern = r'\\s(\\d{3})\\s'\n\ndf_log = log_raw.select(regexp_extract('value', host_pattern, 1).alias('host'),\n                         regexp_extract('value', ts_pattern, 1).alias('timestamp'),\n                         regexp_extract('value', method_uri_protocol_pattern, 1).alias('method'),\n                         regexp_extract('value', method_uri_protocol_pattern, 2).alias('endpoint'),\n                         regexp_extract('value', method_uri_protocol_pattern, 3).alias('protocol'),\n                         regexp_extract('value', status_pattern, 1).cast('integer').alias('status'))\n\ndf_log.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3202d400-79d6-4487-9df0-e1d3d72e3462"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"log_raw","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"value","nullable":true,"type":"string"}],"type":"struct"},"tableIdentifier":null},{"name":"df_log","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"host","nullable":true,"type":"string"},{"metadata":{},"name":"timestamp","nullable":true,"type":"string"},{"metadata":{},"name":"method","nullable":true,"type":"string"},{"metadata":{},"name":"endpoint","nullable":true,"type":"string"},{"metadata":{},"name":"protocol","nullable":true,"type":"string"},{"metadata":{},"name":"status","nullable":true,"type":"integer"}],"type":"struct"},"tableIdentifier":null}],"data":"<div class=\"ansiout\">+--------------+--------------------+------+---------------+--------+------+\n|          host|           timestamp|method|       endpoint|protocol|status|\n+--------------+--------------------+------+---------------+--------+------+\n| 71.19.157.174|24/Sep/2014:22:26...|   GET|         /error|HTTP/1.1|   404|\n| 10.100.200.30|25/Sep/2014:22:26...|   GET| /history/apolo|HTTP/1.1|   200|\n| 25.100.30.450|25/Sep/2014:23:03...|   GET| /ripley/tienda|HTTP/1.1|   200|\n| 25.100.30.450|26/Sep/2014:08:26...|   GET|  /ripley/banco|HTTP/1.1|   200|\n| 25.100.30.450|26/Sep/2014:08:30...|   GET|/ripley/landing|HTTP/1.1|   200|\n| 10.100.200.30|27/Sep/2014:09:25...|   GET|    /sbp/puntos|HTTP/1.1|   200|\n| 71.19.157.174|27/Sep/2014:22:26...|   GET|    /bdt/huerut|HTTP/1.1|   200|\n| 71.19.157.174|27/Sep/2014:22:26...|   GET|         /error|HTTP/1.1|   404|\n| 71.19.157.174|28/Sep/2014:22:26...|   GET|         /error|HTTP/1.1|   404|\n| 71.19.157.174|29/Sep/2014:22:26...|   GET|         /error|HTTP/1.1|   404|\n| 71.19.157.174|30/Sep/2014:22:26...|   GET|         /error|HTTP/1.1|   404|\n|10.100.120.130|01/Oct/2014:22:26...|   GET|         /error|HTTP/1.1|   404|\n| 71.19.157.174|02/Oct/2014:22:26...|   GET|         /error|HTTP/1.1|   404|\n| 71.19.157.174|03/Oct/2014:22:26...|   GET|         /error|HTTP/1.1|   404|\n| 25.100.30.450|04/Oct/2014:22:26...|   GET|         /error|HTTP/1.1|   404|\n| 25.100.30.450|05/Oct/2014:22:26...|   GET|         /error|HTTP/1.1|   404|\n| 10.10.150.100|06/Oct/2014:22:26...|   GET|         /error|HTTP/1.1|   404|\n| 10.10.160.100|07/Oct/2014:22:26...|   GET|         /error|HTTP/1.1|   404|\n| 10.10.192.168|08/Oct/2014:22:26...|   GET|         /error|HTTP/1.1|   404|\n| 71.19.157.174|09/Oct/2014:22:26...|   GET|         /error|HTTP/1.1|   404|\n+--------------+--------------------+------+---------------+--------+------+\nonly showing top 20 rows\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------+--------------------+------+---------------+--------+------+\n          host|           timestamp|method|       endpoint|protocol|status|\n+--------------+--------------------+------+---------------+--------+------+\n 71.19.157.174|24/Sep/2014:22:26...|   GET|         /error|HTTP/1.1|   404|\n 10.100.200.30|25/Sep/2014:22:26...|   GET| /history/apolo|HTTP/1.1|   200|\n 25.100.30.450|25/Sep/2014:23:03...|   GET| /ripley/tienda|HTTP/1.1|   200|\n 25.100.30.450|26/Sep/2014:08:26...|   GET|  /ripley/banco|HTTP/1.1|   200|\n 25.100.30.450|26/Sep/2014:08:30...|   GET|/ripley/landing|HTTP/1.1|   200|\n 10.100.200.30|27/Sep/2014:09:25...|   GET|    /sbp/puntos|HTTP/1.1|   200|\n 71.19.157.174|27/Sep/2014:22:26...|   GET|    /bdt/huerut|HTTP/1.1|   200|\n 71.19.157.174|27/Sep/2014:22:26...|   GET|         /error|HTTP/1.1|   404|\n 71.19.157.174|28/Sep/2014:22:26...|   GET|         /error|HTTP/1.1|   404|\n 71.19.157.174|29/Sep/2014:22:26...|   GET|         /error|HTTP/1.1|   404|\n 71.19.157.174|30/Sep/2014:22:26...|   GET|         /error|HTTP/1.1|   404|\n10.100.120.130|01/Oct/2014:22:26...|   GET|         /error|HTTP/1.1|   404|\n 71.19.157.174|02/Oct/2014:22:26...|   GET|         /error|HTTP/1.1|   404|\n 71.19.157.174|03/Oct/2014:22:26...|   GET|         /error|HTTP/1.1|   404|\n 25.100.30.450|04/Oct/2014:22:26...|   GET|         /error|HTTP/1.1|   404|\n 25.100.30.450|05/Oct/2014:22:26...|   GET|         /error|HTTP/1.1|   404|\n 10.10.150.100|06/Oct/2014:22:26...|   GET|         /error|HTTP/1.1|   404|\n 10.10.160.100|07/Oct/2014:22:26...|   GET|         /error|HTTP/1.1|   404|\n 10.10.192.168|08/Oct/2014:22:26...|   GET|         /error|HTTP/1.1|   404|\n 71.19.157.174|09/Oct/2014:22:26...|   GET|         /error|HTTP/1.1|   404|\n+--------------+--------------------+------+---------------+--------+------+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["<h1>CSV Parsing</h1>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"98e664d6-de79-48e3-9cf1-f1b16dcd6325"}}},{"cell_type":"markdown","source":["Question #1: CSV Header Rows"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a1aa4786-c292-4ca4-96f4-d34d0cd65858"}}},{"cell_type":"code","source":["%scala\n//Question #1:Question #1: CSV Header Rows\nval full_csv = sc.parallelize(Array(\n\"col_1, col_2, col_3\",\n\"1, ABC, Foo1\",\n\"2, ABCD, Foo2\",\n\"3, ABCDE, Foo3\",\n\"4, ABCDEF, Foo4\",\n\"5, DEF, Foo5\",\n\"6, DEFGHI, Foo6\",\n\"7, GHI, Foo7\",\n\"8, GHIJKL, Foo8\",\n\"9, JKLMNO, Foo9\",\n\"10, MNO, Foo10\"))\n\nval data_without_header = full_csv.mapPartitionsWithIndex {\n  (idx, iter) => if (idx == 0) iter.drop(1) else iter \n}\ndata_without_header.collect()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"571f9d9f-d49e-4c7e-a36f-7be9746155f6"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">full_csv: org.apache.spark.rdd.RDD[String] = ParallelCollectionRDD[44] at parallelize at command-3611561463677179:2\ndata_without_header: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[45] at mapPartitionsWithIndex at command-3611561463677179:15\nres1: Array[String] = Array(1, ABC, Foo1, 2, ABCD, Foo2, 3, ABCDE, Foo3, 4, ABCDEF, Foo4, 5, DEF, Foo5, 6, DEFGHI, Foo6, 7, GHI, Foo7, 8, GHIJKL, Foo8, 9, JKLMNO, Foo9, 10, MNO, Foo10)\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">full_csv: org.apache.spark.rdd.RDD[String] = ParallelCollectionRDD[44] at parallelize at command-3611561463677179:2\ndata_without_header: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[45] at mapPartitionsWithIndex at command-3611561463677179:15\nres1: Array[String] = Array(1, ABC, Foo1, 2, ABCD, Foo2, 3, ABCDE, Foo3, 4, ABCDEF, Foo4, 5, DEF, Foo5, 6, DEFGHI, Foo6, 7, GHI, Foo7, 8, GHIJKL, Foo8, 9, JKLMNO, Foo9, 10, MNO, Foo10)\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Question # 2 SparkSQL Dataframes"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"753d1863-67b3-4dd2-a3b0-e9f7448d52fb"}}},{"cell_type":"code","source":["%scala\n// Question # 2 SparkSQL Dataframes\n// Se utiliza el RDD sin el header\nval full_csv_row = data_without_header.map(f => {f.split(\",\")}).map {\n      case Array(columna1, columna2,columna3) =>\n        Row(columna1.toInt, columna2,columna3)\n    }\nval schema: StructType = StructType(Array(\n      StructField(\"Columna1\", IntegerType, true),\n      StructField(\"Columna2\", StringType, true),\n      StructField(\"Columna3\", StringType, true)\n    ))\nval df_full_csv = spark.createDataFrame(full_csv_row, schema)\ndf_full_csv.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2ac24767-0e2c-48f9-854a-60645637098a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"df_full_csv","typeStr":"org.apache.spark.sql.DataFrame","schema":{"type":"struct","fields":[{"name":"Columna1","type":"integer","nullable":true,"metadata":{}},{"name":"Columna2","type":"string","nullable":true,"metadata":{}},{"name":"Columna3","type":"string","nullable":true,"metadata":{}}]},"tableIdentifier":null}],"data":"<div class=\"ansiout\">+--------+--------+--------+\n|Columna1|Columna2|Columna3|\n+--------+--------+--------+\n|       1|     ABC|    Foo1|\n|       2|    ABCD|    Foo2|\n|       3|   ABCDE|    Foo3|\n|       4|  ABCDEF|    Foo4|\n|       5|     DEF|    Foo5|\n|       6|  DEFGHI|    Foo6|\n|       7|     GHI|    Foo7|\n|       8|  GHIJKL|    Foo8|\n|       9|  JKLMNO|    Foo9|\n|      10|     MNO|   Foo10|\n+--------+--------+--------+\n\nfull_csv_row: org.apache.spark.rdd.RDD[org.apache.spark.sql.Row] = MapPartitionsRDD[47] at map at command-209898474111962:3\nschema: org.apache.spark.sql.types.StructType = StructType(StructField(Columna1,IntegerType,true), StructField(Columna2,StringType,true), StructField(Columna3,StringType,true))\ndf_full_csv: org.apache.spark.sql.DataFrame = [Columna1: int, Columna2: string ... 1 more field]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------+--------+--------+\nColumna1|Columna2|Columna3|\n+--------+--------+--------+\n       1|     ABC|    Foo1|\n       2|    ABCD|    Foo2|\n       3|   ABCDE|    Foo3|\n       4|  ABCDEF|    Foo4|\n       5|     DEF|    Foo5|\n       6|  DEFGHI|    Foo6|\n       7|     GHI|    Foo7|\n       8|  GHIJKL|    Foo8|\n       9|  JKLMNO|    Foo9|\n      10|     MNO|   Foo10|\n+--------+--------+--------+\n\nfull_csv_row: org.apache.spark.rdd.RDD[org.apache.spark.sql.Row] = MapPartitionsRDD[47] at map at command-209898474111962:3\nschema: org.apache.spark.sql.types.StructType = StructType(StructField(Columna1,IntegerType,true), StructField(Columna2,StringType,true), StructField(Columna3,StringType,true))\ndf_full_csv: org.apache.spark.sql.DataFrame = [Columna1: int, Columna2: string ... 1 more field]\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Question # 3 Parsing Pairs"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e2644aa1-8014-494b-8540-d525db1c088a"}}},{"cell_type":"code","source":["#Genera el archivo plano para el siguiente ejercicio.\nimport os\nfile = open(\"/dbfs/tmp/file_KeyPairs.txt\", \"w\")\nfile.write(\"Row-Key-001, K1, 10, A2, 20, K3, 30, B4, 42, K5, 19, C20, 20\" + os.linesep)\nfile.write(\"Row-Key-002, X1, 20, Y6, 10, Z15, 35, X16, 42\" + os.linesep )\nfile.write(\"Row-Key-003, L4, 30, M10, 5, N12, 38, O14, 41, P13, 8\" )\nfile.close()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2ff0a177-fcd1-4ea3-ac8f-839c3b7366e2"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["%scala\n/* Question # 3 Parsing Pairs\nWrite a Spark job that processes comma-separated lines that look like the below example to pull out Key Value pairs.\nGiven the following data:\nRow-Key-001, K1, 10, A2, 20, K3, 30, B4, 42, K5, 19, C20, 20\nRow-Key-002, X1, 20, Y6, 10, Z15, 35, X16, 42\nRow-Key-003, L4, 30, M10, 5, N12, 38, O14, 41, P13, 8\n*/\n//Nota: Para este ejercicio los datos se guardaron en un archivo plano.\nval rdd_text_file = sc.textFile(\"/tmp/file_KeyPairs.txt\")\nval rdd_key_pairs = rdd_text_file.map(_.split(\", \")).flatMap(x =>  x.tail.grouped(2).map(y => (x.head, y.head)))\nval df_key_pairs = rdd_key_pairs.toDF(\"Clave\",\"Valor\")\ndf_key_pairs.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2910a235-99de-47fd-8270-1f6504c044e4"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"df_key_pairs","typeStr":"org.apache.spark.sql.DataFrame","schema":{"type":"struct","fields":[{"name":"Clave","type":"string","nullable":true,"metadata":{}},{"name":"Valor","type":"string","nullable":true,"metadata":{}}]},"tableIdentifier":null}],"data":"<div class=\"ansiout\">+-----------+-----+\n|      Clave|Valor|\n+-----------+-----+\n|Row-Key-001|   K1|\n|Row-Key-001|   A2|\n|Row-Key-001|   K3|\n|Row-Key-001|   B4|\n|Row-Key-001|   K5|\n|Row-Key-001|  C20|\n|Row-Key-002|   X1|\n|Row-Key-002|   Y6|\n|Row-Key-002|  Z15|\n|Row-Key-002|  X16|\n|Row-Key-003|   L4|\n|Row-Key-003|  M10|\n|Row-Key-003|  N12|\n|Row-Key-003|  O14|\n|Row-Key-003|  P13|\n+-----------+-----+\n\nrdd_text_file: org.apache.spark.rdd.RDD[String] = /FileStore/file_question3.txt MapPartitionsRDD[68] at textFile at command-2334682895293762:9\nrdd_key_pairs: org.apache.spark.rdd.RDD[(String, String)] = MapPartitionsRDD[70] at flatMap at command-2334682895293762:10\ndf_key_pairs: org.apache.spark.sql.DataFrame = [Clave: string, Valor: string]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----------+-----+\n      Clave|Valor|\n+-----------+-----+\nRow-Key-001|   K1|\nRow-Key-001|   A2|\nRow-Key-001|   K3|\nRow-Key-001|   B4|\nRow-Key-001|   K5|\nRow-Key-001|  C20|\nRow-Key-002|   X1|\nRow-Key-002|   Y6|\nRow-Key-002|  Z15|\nRow-Key-002|  X16|\nRow-Key-003|   L4|\nRow-Key-003|  M10|\nRow-Key-003|  N12|\nRow-Key-003|  O14|\nRow-Key-003|  P13|\n+-----------+-----+\n\nrdd_text_file: org.apache.spark.rdd.RDD[String] = /FileStore/file_question3.txt MapPartitionsRDD[68] at textFile at command-2334682895293762:9\nrdd_key_pairs: org.apache.spark.rdd.RDD[(String, String)] = MapPartitionsRDD[70] at flatMap at command-2334682895293762:10\ndf_key_pairs: org.apache.spark.sql.DataFrame = [Clave: string, Valor: string]\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Question # 4 Create Tables Programmatically And Cache The Table"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a5821793-62be-4fc8-9df1-1c6f47ee69e2"}}},{"cell_type":"code","source":["%scala\n//Question # 4 Create Tables Programmatically And Cache The Table\n//Utilizando el dataframe creado en la pregunta #2 (df_full_csv)  se genera una tabla utilizando  write.saveAsTable()\ndf_full_csv.write.saveAsTable(\"TB_full_csv\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a1f20bc2-7a52-4f36-9f4d-40214cf494f9"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"<div class=\"ansiout\">\tat org.apache.spark.sql.DataFrameWriter.saveAsTable(DataFrameWriter.scala:704)\n\tat org.apache.spark.sql.DataFrameWriter.saveAsTable(DataFrameWriter.scala:625)\n\tat linecc3f46f141834720977663c5b54bab4337.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw.&lt;init&gt;(command-1210462427365216:3)\n\tat linecc3f46f141834720977663c5b54bab4337.$read$$iw$$iw$$iw$$iw$$iw$$iw.&lt;init&gt;(command-1210462427365216:55)\n\tat linecc3f46f141834720977663c5b54bab4337.$read$$iw$$iw$$iw$$iw$$iw.&lt;init&gt;(command-1210462427365216:57)\n\tat linecc3f46f141834720977663c5b54bab4337.$read$$iw$$iw$$iw$$iw.&lt;init&gt;(command-1210462427365216:59)\n\tat linecc3f46f141834720977663c5b54bab4337.$read$$iw$$iw$$iw.&lt;init&gt;(command-1210462427365216:61)\n\tat linecc3f46f141834720977663c5b54bab4337.$read$$iw$$iw.&lt;init&gt;(command-1210462427365216:63)\n\tat linecc3f46f141834720977663c5b54bab4337.$read$$iw.&lt;init&gt;(command-1210462427365216:65)\n\tat linecc3f46f141834720977663c5b54bab4337.$read.&lt;init&gt;(command-1210462427365216:67)\n\tat linecc3f46f141834720977663c5b54bab4337.$read$.&lt;init&gt;(command-1210462427365216:71)\n\tat linecc3f46f141834720977663c5b54bab4337.$read$.&lt;clinit&gt;(command-1210462427365216)\n\tat linecc3f46f141834720977663c5b54bab4337.$eval$.$print$lzycompute(&lt;notebook&gt;:7)\n\tat linecc3f46f141834720977663c5b54bab4337.$eval$.$print(&lt;notebook&gt;:6)\n\tat linecc3f46f141834720977663c5b54bab4337.$eval.$print(&lt;notebook&gt;)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat scala.tools.nsc.interpreter.IMain$ReadEvalPrint.call(IMain.scala:745)\n\tat scala.tools.nsc.interpreter.IMain$Request.loadAndRun(IMain.scala:1021)\n\tat scala.tools.nsc.interpreter.IMain.$anonfun$interpret$1(IMain.scala:574)\n\tat scala.reflect.internal.util.ScalaClassLoader.asContext(ScalaClassLoader.scala:41)\n\tat scala.reflect.internal.util.ScalaClassLoader.asContext$(ScalaClassLoader.scala:37)\n\tat scala.reflect.internal.util.AbstractFileClassLoader.asContext(AbstractFileClassLoader.scala:41)\n\tat scala.tools.nsc.interpreter.IMain.loadAndRunReq$1(IMain.scala:573)\n\tat scala.tools.nsc.interpreter.IMain.interpret(IMain.scala:600)\n\tat scala.tools.nsc.interpreter.IMain.interpret(IMain.scala:570)\n\tat com.databricks.backend.daemon.driver.DriverILoop.execute(DriverILoop.scala:219)\n\tat com.databricks.backend.daemon.driver.ScalaDriverLocal.$anonfun$repl$1(ScalaDriverLocal.scala:204)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.backend.daemon.driver.DriverLocal$TrapExitInternal$.trapExit(DriverLocal.scala:789)\n\tat com.databricks.backend.daemon.driver.DriverLocal$TrapExit$.apply(DriverLocal.scala:742)\n\tat com.databricks.backend.daemon.driver.ScalaDriverLocal.repl(ScalaDriverLocal.scala:204)\n\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$10(DriverLocal.scala:431)\n\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:239)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:234)\n\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:231)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionContext(DriverLocal.scala:48)\n\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:276)\n\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:269)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionTags(DriverLocal.scala:48)\n\tat com.databricks.backend.daemon.driver.DriverLocal.execute(DriverLocal.scala:408)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$1(DriverWrapper.scala:653)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.tryExecutingCommand(DriverWrapper.scala:645)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.getCommandOutputAndError(DriverWrapper.scala:486)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommand(DriverWrapper.scala:598)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInnerLoop(DriverWrapper.scala:391)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInner(DriverWrapper.scala:337)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:219)\n\tat java.lang.Thread.run(Thread.java:748)</div>","errorSummary":"org.apache.spark.sql.AnalysisException: Table `TB_full_csv` already exists.;","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">\tat org.apache.spark.sql.DataFrameWriter.saveAsTable(DataFrameWriter.scala:704)\n\tat org.apache.spark.sql.DataFrameWriter.saveAsTable(DataFrameWriter.scala:625)\n\tat linecc3f46f141834720977663c5b54bab4337.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw.&lt;init&gt;(command-1210462427365216:3)\n\tat linecc3f46f141834720977663c5b54bab4337.$read$$iw$$iw$$iw$$iw$$iw$$iw.&lt;init&gt;(command-1210462427365216:55)\n\tat linecc3f46f141834720977663c5b54bab4337.$read$$iw$$iw$$iw$$iw$$iw.&lt;init&gt;(command-1210462427365216:57)\n\tat linecc3f46f141834720977663c5b54bab4337.$read$$iw$$iw$$iw$$iw.&lt;init&gt;(command-1210462427365216:59)\n\tat linecc3f46f141834720977663c5b54bab4337.$read$$iw$$iw$$iw.&lt;init&gt;(command-1210462427365216:61)\n\tat linecc3f46f141834720977663c5b54bab4337.$read$$iw$$iw.&lt;init&gt;(command-1210462427365216:63)\n\tat linecc3f46f141834720977663c5b54bab4337.$read$$iw.&lt;init&gt;(command-1210462427365216:65)\n\tat linecc3f46f141834720977663c5b54bab4337.$read.&lt;init&gt;(command-1210462427365216:67)\n\tat linecc3f46f141834720977663c5b54bab4337.$read$.&lt;init&gt;(command-1210462427365216:71)\n\tat linecc3f46f141834720977663c5b54bab4337.$read$.&lt;clinit&gt;(command-1210462427365216)\n\tat linecc3f46f141834720977663c5b54bab4337.$eval$.$print$lzycompute(&lt;notebook&gt;:7)\n\tat linecc3f46f141834720977663c5b54bab4337.$eval$.$print(&lt;notebook&gt;:6)\n\tat linecc3f46f141834720977663c5b54bab4337.$eval.$print(&lt;notebook&gt;)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat scala.tools.nsc.interpreter.IMain$ReadEvalPrint.call(IMain.scala:745)\n\tat scala.tools.nsc.interpreter.IMain$Request.loadAndRun(IMain.scala:1021)\n\tat scala.tools.nsc.interpreter.IMain.$anonfun$interpret$1(IMain.scala:574)\n\tat scala.reflect.internal.util.ScalaClassLoader.asContext(ScalaClassLoader.scala:41)\n\tat scala.reflect.internal.util.ScalaClassLoader.asContext$(ScalaClassLoader.scala:37)\n\tat scala.reflect.internal.util.AbstractFileClassLoader.asContext(AbstractFileClassLoader.scala:41)\n\tat scala.tools.nsc.interpreter.IMain.loadAndRunReq$1(IMain.scala:573)\n\tat scala.tools.nsc.interpreter.IMain.interpret(IMain.scala:600)\n\tat scala.tools.nsc.interpreter.IMain.interpret(IMain.scala:570)\n\tat com.databricks.backend.daemon.driver.DriverILoop.execute(DriverILoop.scala:219)\n\tat com.databricks.backend.daemon.driver.ScalaDriverLocal.$anonfun$repl$1(ScalaDriverLocal.scala:204)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.backend.daemon.driver.DriverLocal$TrapExitInternal$.trapExit(DriverLocal.scala:789)\n\tat com.databricks.backend.daemon.driver.DriverLocal$TrapExit$.apply(DriverLocal.scala:742)\n\tat com.databricks.backend.daemon.driver.ScalaDriverLocal.repl(ScalaDriverLocal.scala:204)\n\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$10(DriverLocal.scala:431)\n\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:239)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:234)\n\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:231)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionContext(DriverLocal.scala:48)\n\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:276)\n\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:269)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionTags(DriverLocal.scala:48)\n\tat com.databricks.backend.daemon.driver.DriverLocal.execute(DriverLocal.scala:408)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$1(DriverWrapper.scala:653)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.tryExecutingCommand(DriverWrapper.scala:645)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.getCommandOutputAndError(DriverWrapper.scala:486)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommand(DriverWrapper.scala:598)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInnerLoop(DriverWrapper.scala:391)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInner(DriverWrapper.scala:337)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:219)\n\tat java.lang.Thread.run(Thread.java:748)</div>"]}}],"execution_count":0},{"cell_type":"code","source":["%sql\nselect * from TB_full_csv"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"956bf439-55c6-4f96-8681-707924b21299"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[[1," ABC"," Foo1"],[8," GHIJKL"," Foo8"],[9," JKLMNO"," Foo9"],[10," MNO"," Foo10"],[2," ABCD"," Foo2"],[3," ABCDE"," Foo3"],[4," ABCDEF"," Foo4"],[5," DEF"," Foo5"],[6," DEFGHI"," Foo6"],[7," GHI"," Foo7"]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"Columna1","type":"\"integer\"","metadata":"{}"},{"name":"Columna2","type":"\"string\"","metadata":"{}"},{"name":"Columna3","type":"\"string\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Columna1</th><th>Columna2</th><th>Columna3</th></tr></thead><tbody><tr><td>1</td><td> ABC</td><td> Foo1</td></tr><tr><td>8</td><td> GHIJKL</td><td> Foo8</td></tr><tr><td>9</td><td> JKLMNO</td><td> Foo9</td></tr><tr><td>10</td><td> MNO</td><td> Foo10</td></tr><tr><td>2</td><td> ABCD</td><td> Foo2</td></tr><tr><td>3</td><td> ABCDE</td><td> Foo3</td></tr><tr><td>4</td><td> ABCDEF</td><td> Foo4</td></tr><tr><td>5</td><td> DEF</td><td> Foo5</td></tr><tr><td>6</td><td> DEFGHI</td><td> Foo6</td></tr><tr><td>7</td><td> GHI</td><td> Foo7</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Temporary Tables<br>\n<li>Within each Spark cluster, temporary tables registered in the sqlContext with DataFrame.registerTempTable will also be shared across the notebooks attached to that Databricks cluster\n<li>Run someDataFrame.registerTempTable(TEMP_TABLE_NAME) to give register a table.\n<li>These tables will not be visible in the left-hand menu, but can be accessed by name in SQL and DataFrames."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"63a28b54-785f-481a-ad3c-9421bd27c8dc"}}},{"cell_type":"code","source":["%scala\n//Temporary Tables en Question #1 se crean dos tablas temporales que no son almacenadas en el workspace de databricks, pero si pueden ser consultadas en el contexto de spark.\n//Se utiliza el dataframe creado en la pregunta 3\ndf_key_pairs.createOrReplaceTempView(\"tb_tmp_key_pairs\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"eda59a48-8160-4c46-967e-2c0fbf7751fa"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["%sql\n/*De la tabla creada anteriormente es posible consultarla con sql, esta tabla no se guarda en el espacio de trabajo de databricks*/\nSelect * from tb_tmp_key_pairs;"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"29911580-8c8e-4482-997b-c712da080586"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["Row-Key-001","K1"],["Row-Key-001","A2"],["Row-Key-001","K3"],["Row-Key-001","B4"],["Row-Key-001","K5"],["Row-Key-001","C20"],["Row-Key-002","X1"],["Row-Key-002","Y6"],["Row-Key-002","Z15"],["Row-Key-002","X16"],["Row-Key-003","L4"],["Row-Key-003","M10"],["Row-Key-003","N12"],["Row-Key-003","O14"],["Row-Key-003","P13"]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"Clave","type":"\"string\"","metadata":"{}"},{"name":"Valor","type":"\"string\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Clave</th><th>Valor</th></tr></thead><tbody><tr><td>Row-Key-001</td><td>K1</td></tr><tr><td>Row-Key-001</td><td>A2</td></tr><tr><td>Row-Key-001</td><td>K3</td></tr><tr><td>Row-Key-001</td><td>B4</td></tr><tr><td>Row-Key-001</td><td>K5</td></tr><tr><td>Row-Key-001</td><td>C20</td></tr><tr><td>Row-Key-002</td><td>X1</td></tr><tr><td>Row-Key-002</td><td>Y6</td></tr><tr><td>Row-Key-002</td><td>Z15</td></tr><tr><td>Row-Key-002</td><td>X16</td></tr><tr><td>Row-Key-003</td><td>L4</td></tr><tr><td>Row-Key-003</td><td>M10</td></tr><tr><td>Row-Key-003</td><td>N12</td></tr><tr><td>Row-Key-003</td><td>O14</td></tr><tr><td>Row-Key-003</td><td>P13</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"code","source":["#En este caso se trabaja con pyspark el mismo ejercicio, a diferencia del caso anterior que es desarrollado en scala.\nsqlContext.sql(\"select * from tb_full_csv\").registerTempTable(\"tb_tmp_full_csv\")\ndf_temp_full_csv = spark.sql(\"select * from tb_tmp_full_csv\")\ndf_temp_full_csv.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"664075a0-ff91-4242-87a6-af052ca03e54"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"df_temp_full_csv","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"Columna1","nullable":true,"type":"integer"},{"metadata":{},"name":"Columna2","nullable":true,"type":"string"},{"metadata":{},"name":"Columna3","nullable":true,"type":"string"}],"type":"struct"},"tableIdentifier":null}],"data":"<div class=\"ansiout\">+--------+--------+--------+\n|Columna1|Columna2|Columna3|\n+--------+--------+--------+\n|       1|     ABC|    Foo1|\n|       8|  GHIJKL|    Foo8|\n|       9|  JKLMNO|    Foo9|\n|      10|     MNO|   Foo10|\n|       2|    ABCD|    Foo2|\n|       3|   ABCDE|    Foo3|\n|       4|  ABCDEF|    Foo4|\n|       5|     DEF|    Foo5|\n|       6|  DEFGHI|    Foo6|\n|       7|     GHI|    Foo7|\n+--------+--------+--------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------+--------+--------+\nColumna1|Columna2|Columna3|\n+--------+--------+--------+\n       1|     ABC|    Foo1|\n       8|  GHIJKL|    Foo8|\n       9|  JKLMNO|    Foo9|\n      10|     MNO|   Foo10|\n       2|    ABCD|    Foo2|\n       3|   ABCDE|    Foo3|\n       4|  ABCDEF|    Foo4|\n       5|     DEF|    Foo5|\n       6|  DEFGHI|    Foo6|\n       7|     GHI|    Foo7|\n+--------+--------+--------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["<h1>Others</h1>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b40c8681-e1be-483a-b3a9-2a849df619fb"}}},{"cell_type":"markdown","source":["1.\tGiven a data set in raw text storage format. What other data storage format can you suggest optimizing the performance of a Spark workload if we were to frequently scan and read this dataset. Explain why you decide to go with this approach?\n<br>\nAs a data storage format, I would use parquet, it is a format that handles different forms of compression in storage and the way in which the data is saved is columnar, which optimizes data reading.\n\n2.\tYou are given to design a streaming data pipeline on AWS, consuming the data in the form of JSON events from an external producer. The customers consuming this data from the AWS endpoint you provide has a requirement that this data set be structured/normalised and easier to use. What are your tools of choice to design this streaming pipeline, how will you ensure the costs don’t surge, and how will you fulfil the customer’s request?\n<br>\nFor reading the events of the producer I would use AWS lambda (python) to read and process the events, for storage I would use AWS RDS Aurora which are relational databases that allow  to save the normalized and structured data There is not a license cost, only paid for the infrastructure on which the database is implemented and it is managed by AWS, for the information consumption endpoint it would be implemented with API Gateway and lambda to build an API Rest service in python or node code. js."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"acb53dc9-0871-4903-b8b6-ddbf9f134f34"}}},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6c32d7cd-c20e-4768-b016-2e19f5e59c6b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"challenge-bluesmile","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":3611561463677177}},"nbformat":4,"nbformat_minor":0}
